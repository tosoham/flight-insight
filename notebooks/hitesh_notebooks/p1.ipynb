{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import datetime, warnings, scipy \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the DATA SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this notebook, I developed a model aimed at predicting flight delays at the Destination Airport. The purpose is to create a Data set which can be used for visualization and model Building so as to predict the Delays of Flights. I did the visualization so as to get better inferences about the data. For, model fitting I have seperated the Dataset into training Data and Testing Data so that prediction can be done on the testing Data. I also showed how to import Tableau and make visualization more crisp and clear.\n",
    "\n",
    "Technical aspect Covered:\n",
    "\n",
    "visualization: matplolib, seaborn, Tableau\n",
    "\n",
    "data manipulation: pandas, numpy\n",
    "\n",
    "modeling: sklearn\n",
    "\n",
    "class definition: regression, Boosting, Bagging\n",
    "\n",
    "For EDA I used some part of Python coding and Tableau Visulization so as to get a brief insight and inference from the data. Various Plots are created so as to get a great idea of whats happening in the Dataset and what is the most important variable affecting the dalays of the airlines. Feature scaling is a method used to normalize the range of independent variables or features of data and this concept is used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hy3qhkf90ld86v626flq0kb80000gn/T/ipykernel_6364/3981750233.py:1: DtypeWarning: Columns (7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"archive/flights.csv\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"archive/flights.csv\")\n",
    "airport = pd.read_csv('archive/airports.csv')\n",
    "airlines = pd.read_csv('archive/airlines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data Contains 31 columns and 1048575 Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table it is clear that data is not properly organised and date is given seperated and many columns have unnecessary data not useful for visualization for which it is required that we clean the data and take only those columns which is of our use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# airport.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "airport = airport.dropna(subset = ['LATITUDE','LONGITUDE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# airport.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# airport.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Data_NULL = data.isnull().sum()*100/data.shape[0]\n",
    "# Data_NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 96% of the values in Cancellation reason column are null for which it is of less use while predicting Delays. Some other columns include 78.2% in Air System Delay, Security Delay, Airline Delay, Weather Delay etc. So I am going to create two Dataset which is having no null values one is by removing all the null values irrespective of different types of Delays and other I am going to take the data set with respect to different types of delays. The first Dataset is named as Flights and the other one is named as Flight_Delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['AIR_SYSTEM_DELAY','SECURITY_DELAY','AIRLINE_DELAY','LATE_AIRCRAFT_DELAY','WEATHER_DELAY']] = data[['AIR_SYSTEM_DELAY','SECURITY_DELAY','AIRLINE_DELAY','LATE_AIRCRAFT_DELAY','WEATHER_DELAY']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# # Dropping of subset of null values\n",
    "data1 = data.dropna(subset = [\"TAIL_NUMBER\",'DEPARTURE_TIME','DEPARTURE_DELAY','TAXI_OUT','WHEELS_OFF','SCHEDULED_TIME',\n",
    "             'ELAPSED_TIME','AIR_TIME','WHEELS_ON','TAXI_IN','ARRIVAL_TIME','ARRIVAL_DELAY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5714008, 31)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Creting Dataset w.r.t different Types of Delays\n",
    "data11 = data1.dropna(subset = ['AIR_SYSTEM_DELAY','SECURITY_DELAY','AIRLINE_DELAY','LATE_AIRCRAFT_DELAY','WEATHER_DELAY'])\n",
    "# data11 = data1[['AIR_SYSTEM_DELAY','SECURITY_DELAY','AIRLINE_DELAY','LATE_AIRCRAFT_DELAY','WEATHER_DELAY']]\n",
    "data11 = data11.drop(['YEAR','MONTH','DAY','DAY_OF_WEEK','TAIL_NUMBER','SCHEDULED_DEPARTURE','DEPARTURE_TIME','SCHEDULED_TIME',\n",
    "                     'SCHEDULED_ARRIVAL','ARRIVAL_TIME','DIVERTED','CANCELLED','CANCELLATION_REASON','FLIGHT_NUMBER','WHEELS_OFF',\n",
    "                     'WHEELS_ON','AIR_TIME'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# data11.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AIRLINE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
       "       'TAXI_OUT', 'ELAPSED_TIME', 'DISTANCE', 'TAXI_IN', 'ARRIVAL_DELAY',\n",
       "       'AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY',\n",
       "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data11.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# The other Dataset\n",
    "Flight_Delays = data11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Creating Dataset by removing null values by not focussing fully on different types of Delays\n",
    "data2 = data1.drop(['CANCELLATION_REASON','AIR_SYSTEM_DELAY','SECURITY_DELAY','AIRLINE_DELAY',\n",
    "                    'LATE_AIRCRAFT_DELAY','WEATHER_DELAY'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# data2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5714008, 25)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# data2.DEPARTURE_TIME.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# data2.DEPARTURE_TIME.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# data2.DEPARTURE_TIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The departure time above is not very much informative so we are going to change it in the datetime format so that we get a better idea of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Creating a function to change the way of representation of time in the column\n",
    "def Format_Hourmin(hours):\n",
    "        if hours == 2400:\n",
    "            hours = 0\n",
    "        else:\n",
    "            hours = \"{0:04d}\".format(int(hours))\n",
    "            Hourmin = datetime.time(int(hours[0:2]), int(hours[2:4]))\n",
    "            return Hourmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          23:54:00\n",
       "1          00:02:00\n",
       "2          00:18:00\n",
       "3          00:15:00\n",
       "4          00:24:00\n",
       "             ...   \n",
       "5819074    23:55:00\n",
       "5819075    23:55:00\n",
       "5819076    23:50:00\n",
       "5819077    23:53:00\n",
       "5819078    00:14:00\n",
       "Name: Actual_Departure, Length: 5714008, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['Actual_Departure'] =data1['DEPARTURE_TIME'].apply(Format_Hourmin)\n",
    "data2['Actual_Departure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Creating Date in the Datetime format\n",
    "data2['Date'] = pd.to_datetime(data2[['YEAR','MONTH','DAY']])\n",
    "# data2.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "data2['Day'] = data2['Date'].dt.day_name()\n",
    "# data2['Day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Applying the function to required variables in the dataset\n",
    "data2['Actual_Departure'] =data1['DEPARTURE_TIME'].apply(Format_Hourmin)\n",
    "data2['Scheduled_Arrival'] =data1['SCHEDULED_ARRIVAL'].apply(Format_Hourmin)\n",
    "data2['Scheduled_Departure'] =data1['SCHEDULED_DEPARTURE'].apply(Format_Hourmin)\n",
    "data2['Actual_Arrival'] =data1['ARRIVAL_TIME'].apply(Format_Hourmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging of  3 data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are three dataset it is required to merge all the three data set so that we can use it during the visualization in a proper way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Merging on AIRLINE and IATA_CODE\n",
    "data2 = data2.merge(airlines, left_on='AIRLINE', right_on='IATA_CODE', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "data2 = data2.drop(['AIRLINE_x','IATA_CODE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "data2 = data2.rename(columns={\"AIRLINE_y\":\"AIRLINE\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "data2 = data2.merge(airport, left_on='ORIGIN_AIRPORT', right_on='IATA_CODE', how='inner')\n",
    "data2 = data2.merge(airport, left_on='DESTINATION_AIRPORT', right_on='IATA_CODE', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "data2 = data2.drop(['LATITUDE_x', 'LONGITUDE_x',\n",
    "       'STATE_y', 'COUNTRY_y', 'LATITUDE_y', 'LONGITUDE_y','STATE_x', 'COUNTRY_x'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "data2 = data2.rename(columns={'IATA_CODE_x':'Org_Airport_Code','AIRPORT_x':'Org_Airport_Name','CITY_x':'Origin_city',\n",
    "                             'IATA_CODE_y':'Dest_Airport_Code','AIRPORT_y':'Dest_Airport_Name','CITY_y':'Destination_city'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data11.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# we are taking the required data into Account for visualization and the Analysis\n",
    "ReqdData = pd.DataFrame(data2[['AIRLINE','Org_Airport_Name','Origin_city',\n",
    "                               'Dest_Airport_Name','Destination_city','ORIGIN_AIRPORT',\n",
    "                               'DESTINATION_AIRPORT','DISTANCE','Actual_Departure','Date','Day',\n",
    "                               'Scheduled_Departure','DEPARTURE_DELAY','Actual_Arrival','Scheduled_Arrival','ARRIVAL_DELAY',\n",
    "                              'SCHEDULED_TIME','ELAPSED_TIME','AIR_TIME','TAXI_IN','TAXI_OUT','DIVERTED',]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# data2.DEPARTURE_TIME.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "ReqdData = ReqdData.dropna(subset = ['Actual_Departure','Actual_Arrival'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# ReqdData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Cleaned Dataset for visualization and Analysis\n",
    "Flights = ReqdData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 10))\n",
    "# axis = sns.countplot(x=Flights['Origin_city'], data = Flights,\n",
    "#               order=Flights['Origin_city'].value_counts().iloc[:20].index)\n",
    "# axis.set_xticklabels(axis.get_xticklabels(), rotation=90, ha=\"right\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Figure shows that Atlanta has the highest count of flight from origin city "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 10))\n",
    "# axis = sns.countplot(x=Flights['Org_Airport_Name'], data = Flights,\n",
    "#               order=Flights['Org_Airport_Name'].value_counts().iloc[:20].index)\n",
    "# axis.set_xticklabels(axis.get_xticklabels(), rotation=90, ha=\"right\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# axis = plt.subplots(figsize=(10,14))\n",
    "# Name = Flights[\"AIRLINE\"].unique()\n",
    "# size = Flights[\"AIRLINE\"].value_counts()\n",
    "# plt.pie(size,labels=Name,autopct='%5.0f%%')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# axis = plt.subplots(figsize=(10,14))\n",
    "# sns.despine(bottom=True, left=True)\n",
    "# # Observations with Scatter Plot\n",
    "# sns.stripplot(x=\"ARRIVAL_DELAY\", y=\"AIRLINE\",\n",
    "#               data = Flights, dodge=True, jitter=True\n",
    "#             )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "American Airlines Inc has the highest Arrival Delay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flights.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# # Dropping unncecssary columns before prediction\n",
    "Flights1 = Flights.drop(['Org_Airport_Name','Origin_city','Dest_Airport_Name','Destination_city'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AIRLINE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DISTANCE',\n",
       "       'Actual_Departure', 'Date', 'Day', 'Scheduled_Departure',\n",
       "       'DEPARTURE_DELAY', 'Actual_Arrival', 'Scheduled_Arrival',\n",
       "       'ARRIVAL_DELAY', 'SCHEDULED_TIME', 'ELAPSED_TIME', 'AIR_TIME',\n",
       "       'TAXI_IN', 'TAXI_OUT', 'DIVERTED'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flights1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# # To check the Distribution of Air Time\n",
    "# sns.displot(Flights1['AIR_TIME'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# # To check the Distribution of Elapsed Time\n",
    "# sns.displot(Flights1['ELAPSED_TIME'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# # To check the Distribution of Taxi IN\n",
    "# sns.displot(Flights1['TAXI_IN'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# # To check the Distribution of Taxi out\n",
    "# sns.displot(Flights1['TAXI_OUT'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# importing Various regression algorithms \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import Lasso,LinearRegression,Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,BaggingRegressor\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "Las = Lasso()\n",
    "LinR = LinearRegression()\n",
    "Rid = Ridge()\n",
    "Rfc = RandomForestRegressor(random_state=2)\n",
    "Dtc = DecisionTreeRegressor(random_state = 2)\n",
    "Boost_Lin = AdaBoostRegressor(estimator=LinR,random_state=2)\n",
    "Boost_las = AdaBoostRegressor(estimator=Las,random_state=2)\n",
    "Boost_rid = AdaBoostRegressor(estimator=Rid,random_state=2)\n",
    "Bg_Lin = BaggingRegressor(estimator=LinR,random_state=2)\n",
    "Bg_las = BaggingRegressor(estimator=Las,random_state=2)\n",
    "Bg_rid = BaggingRegressor(estimator=Rid,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Label encoding features to change categorical variables into numerical one\n",
    "Flights1['AIRLINE']= le.fit_transform(Flights1['AIRLINE'])\n",
    "Flights1['ORIGIN_AIRPORT'] = le.fit_transform(Flights1['ORIGIN_AIRPORT'])\n",
    "Flights1['DESTINATION_AIRPORT'] = le.fit_transform(Flights1['DESTINATION_AIRPORT'])\n",
    "Flights1['Day'] = le.fit_transform(Flights1['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "Flights1 = Flights1.drop(['Scheduled_Departure','Scheduled_Arrival','Actual_Arrival','Date','Actual_Departure'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "X = Flights1.drop('ARRIVAL_DELAY',axis = 1)\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "y = Flights1['ARRIVAL_DELAY']\n",
    "# y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Splitting into train and test data set\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "sc1=StandardScaler()\n",
    "X_train_sc=sc1.fit_transform(X_train)\n",
    "X_test_sc=sc1.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "Mean Absolute Error: 1.2773244090426017e-06\n",
      "Mean Squared Error: 2.5546470946653774e-06\n",
      "Root Mean Squared Error: 0.0015983263417291781\n",
      "R2 :  0.999999998393613\n"
     ]
    }
   ],
   "source": [
    "model1 = LinR.fit(X_train_sc,y_train)\n",
    "Y1_predict=model1.predict(X_test_sc)\n",
    "print(\"LinearRegression:\")\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, Y1_predict))  \n",
    "print('Mean Squared Error:', mean_squared_error(y_test, Y1_predict))  \n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, Y1_predict)))\n",
    "print('R2 : ',r2_score(y_test, Y1_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# for model, name in zip([Las,LinR,Rid,Dtc,Rfc,Boost_Lin], \n",
    "#      ['Lasso','Linear Regression','Ridge','Decision Tree Regressor','Random forest Regressor','Boosted Linear']):\n",
    "#     model1 = model.fit(X_train_sc,y_train)\n",
    "#     Y_predict=model1.predict(X_test_sc)\n",
    "#     print(name)\n",
    "#     print('Mean Absolute Error:', mean_absolute_error(y_test, Y_predict))  \n",
    "#     print('Mean Squared Error:', mean_squared_error(y_test, Y_predict))  \n",
    "#     print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, Y_predict)))\n",
    "#     print('R2 : ',r2_score(y_test, Y_predict))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model, name in zip([Boost_las,Boost_rid,Bg_Lin,Bg_las,Bg_rid], \n",
    "#      ['Boosted Lasso','Boosted Ridge','Bagged Linear','Bagged Lasso','Bagged Ridge']):\n",
    "#     model1 = model.fit(X_train_sc,y_train)\n",
    "#     Y_predict=model1.predict(X_test_sc)\n",
    "#     print(name)\n",
    "#     print('Mean Absolute Error:', mean_absolute_error(y_test, Y_predict))  \n",
    "#     print('Mean Squared Error:', mean_squared_error(y_test, Y_predict))  \n",
    "#     print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, Y_predict)))\n",
    "#     print('R2 : ',r2_score(y_test, Y_predict))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# for model, name in zip([Las,LinR,Rid,Dtc,Rfc,Boost_Lin,Boost_las,Boost_rid,Bg_Lin,Bg_las,Bg_rid], \n",
    "#      ['Lasso','Linear Regression','Ridge','Random forest Regressor','Decision Tree Regressor','Boosted Linear',\n",
    "#       'Boosted Lasso','Boosted Ridge','Bagged Linear','Bagged Lasso','Bagged Ridge']):\n",
    "#     model1 = model.fit(X_train_sc,y_train)\n",
    "#     Y_predict=model1.predict(X_test_sc)\n",
    "#     print(name)\n",
    "#     plt.scatter(y_test, Y_predict)\n",
    "#     plt.title(\"Model Analysis\")\n",
    "#     plt.xlabel(\"Truth\")\n",
    "#     plt.ylabel(\"Prediction\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When Flight_Delays is taken, where I took all the different Delays into Concern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I removed the null values present in all the different types of Delays and proceeded with prediction of the Arrival Delays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# axis = plt.subplots(figsize=(10,14))\n",
    "# Name = Flight_Delays[\"AIRLINE\"].unique()\n",
    "# size = Flight_Delays[\"AIRLINE\"].value_counts()\n",
    "# plt.pie(size,labels=Name,autopct='%5.0f%%')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AIRLINE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DISTANCE', 'Day',\n",
       "       'DEPARTURE_DELAY', 'ARRIVAL_DELAY', 'SCHEDULED_TIME', 'ELAPSED_TIME',\n",
       "       'AIR_TIME', 'TAXI_IN', 'TAXI_OUT', 'DIVERTED'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flights1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AIRLINE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY',\n",
       "       'TAXI_OUT', 'ELAPSED_TIME', 'DISTANCE', 'TAXI_IN', 'ARRIVAL_DELAY',\n",
       "       'AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY',\n",
       "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flight_Delays.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Flight_Delays['ORIGIN_AIRPORT'] = Flight_Delays['ORIGIN_AIRPORT'].astype(str)\n",
    "Flight_Delays['DESTINATION_AIRPORT'] = Flight_Delays['DESTINATION_AIRPORT'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "Flight_Delays['AIRLINE']= le.fit_transform(Flight_Delays['AIRLINE'])\n",
    "Flight_Delays['ORIGIN_AIRPORT'] = le.fit_transform(Flight_Delays['ORIGIN_AIRPORT'])\n",
    "Flight_Delays['DESTINATION_AIRPORT'] = le.fit_transform(Flight_Delays['DESTINATION_AIRPORT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "X = Flight_Delays.drop('ARRIVAL_DELAY',axis = 1)\n",
    "# X.shape\n",
    "y = Flight_Delays['ARRIVAL_DELAY']\n",
    "# y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Splitting the Data into Training and Testing set\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Scalling of the Data\n",
    "sc1=StandardScaler()\n",
    "X_train_sc=sc1.fit_transform(X_train)\n",
    "X_test_sc=sc1.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression:\n",
      "Mean Absolute Error: 6.199613900623898\n",
      "Mean Squared Error: 65.09826201877826\n",
      "Root Mean Squared Error: 8.068349398655108\n",
      "R2 :  0.9573417498642477\n"
     ]
    }
   ],
   "source": [
    "model1 = Rid.fit(X_train_sc,y_train)\n",
    "Y2_predict=model1.predict(X_test_sc)\n",
    "print(\"Ridge Regression:\")\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, Y2_predict))  \n",
    "print('Mean Squared Error:', mean_squared_error(y_test, Y2_predict))  \n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, Y2_predict)))\n",
    "print('R2 : ',r2_score(y_test, Y2_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# for model, name in zip([Las,LinR,Rid,Dtc,Rfc,Boost_Lin,Boost_las,Boost_rid,Bg_Lin,Bg_las,Bg_rid], \n",
    "#      ['Lasso','Linear Regression','Ridge','Random forest Regressor','Decision Tree Regressor','Boosted Linear',\n",
    "#       'Boosted Lasso','Boosted Ridge','Bagged Linear','Bagged Lasso','Bagged Ridge']):\n",
    "#     model1 = model.fit(X_train_sc,y_train)\n",
    "#     Y_predict=model1.predict(X_test_sc)\n",
    "#     print(name)\n",
    "#     print('Mean Absolute Error:', mean_absolute_error(y_test, Y_predict))  \n",
    "#     print('Mean Squared Error:', mean_squared_error(y_test, Y_predict))  \n",
    "#     print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, Y_predict)))\n",
    "#     print('R2 : ',r2_score(y_test, Y_predict))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# for model, name in zip([Las,LinR,Rid,Dtc,Rfc,Boost_Lin,Boost_las,Boost_rid,Bg_Lin,Bg_las,Bg_rid], \n",
    "#      ['Lasso','Linear Regression','Ridge','Random forest Regressor','Decision Tree Regressor','Boosted Linear',\n",
    "#       'Boosted Lasso','Boosted Ridge','Bagged Linear','Bagged Lasso','Bagged Ridge']):\n",
    "#     model1 = model.fit(X_train_sc,y_train)\n",
    "#     Y_predict=model1.predict(X_test_sc)\n",
    "#     print(name)\n",
    "#     plt.scatter(y_test, Y_predict)\n",
    "#     plt.title(\"Model Analysis\")\n",
    "#     plt.xlabel(\"Truth\")\n",
    "#     plt.ylabel(\"Prediction\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that maximum arrival Delays are dependent on the Departure Delays of the Airport. The first part is dealt with cleaning and exploration of the data set to get more insights and the second part dealt with the sitting of the model to predict the delays. For exploratory Analysis I used visualization tools like tableau and seaborn as well as matplotlib. The Second part dealt with the model fitting and predicting the Arrival delays of the airlines.\n",
    "\n",
    "We can see that departure delay is the main problem which is creating Delay in the aviation industry. Departure Delays can be caused due Security Delay, Airline System Delays, Airlines Delay etc. The Delays affect the revenue of the company to a great extent so the delays has to be reduced as much as possible so as to increase the profitability in the Airline Industry. Customer Satisfaction will also be greatly enhanced if the delays can be brought down as low as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing one model per dataset\n",
    "\n",
    "Since we want just one per dataset (not 15 models), here’s what makes sense:\n",
    "\n",
    "Without Delays Dataset → Linear Regression \n",
    "\n",
    "Linear Regression already explains almost all variance with negligible error.\n",
    "\n",
    "Bagging doesn’t add much, so plain Linear Regression is simple & effective.\n",
    "\n",
    "With Delays Dataset → Ridge Regression \n",
    "\n",
    "Linear Regression also performs perfectly here, but Ridge adds stability against collinearity and small noise.\n",
    "\n",
    "Since your dataset may have correlated features, Ridge would be slightly safer long-term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 810,
     "sourceId": 1496,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 29661,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
